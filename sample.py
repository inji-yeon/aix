import streamlit as st
from utils import print_messages, StreamHandler
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

api_key = st.secrets["OPENAI_API_KEY"]

st.set_page_config(page_title="ChatGPT", page_icon="ğŸ¢")
st.title("ğŸ¢ ChatGPT")

if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ì±„íŒ… ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” store ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜
if "store" not in st.session_state:
    st.session_state["store"] = dict()

with st.sidebar:
    session_id = st.text_input("Session ID", value="abc123")

    clear_btn = st.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”")
    if clear_btn:
        st.session_state["messages"] = []
        st.experimental_rerun()
        
# local DBì— ëŒ€í™” ê¸°ë¡ ì €ì¥í•˜ê³  ì‹¶ìœ¼ë©´ Redis

# ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ì¶œë ¥í•´ì£¼ëŠ” ì½”ë“œ
print_messages()

# store = {} # ì„¸ì…˜ ê¸°ë¡ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ 

# ì„¸ì…˜ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_session_history(session_ids: str) -> BaseChatMessageHistory:
    # print(session_ids)
    if session_ids not in st.session_state["store"]: # ì„¸ì…˜ IDê°€ storeì— ì—†ëŠ” ê²½ìš°
        # ìƒˆë¡œìš´ ChatMessageHistory ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ storeì— ì €ì¥
        st.session_state["store"][session_ids] = ChatMessageHistory()
    return st.session_state["store"][session_ids] # í•´ë‹¹ ì„¸ì…˜ IDì— ëŒ€í•œ ì„¸ì…˜ ê¸°ë¡ ë°˜í™˜

if user_input := st.chat_input("Say something"):
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©
    st.chat_message("user").write(f"{user_input}")
    # st.session_state["messages"].append(("user", user_input))
    st.session_state["messages"].append(ChatMessage(role="user", content=user_input))
    
 

    # AIì˜ ë‹µë³€
    with st.chat_message("assistant"):
        # msg = f"your input: {user_input}"
        stream_handler = StreamHandler(st.empty())

           # LLMì„ ì‚¬ìš©í•˜ì—¬ AI ë‹µë³€ì„ ìƒì„±
    #     prompt = ChatPromptTemplate.from_template(
    #         """ì§ˆë¬¸ì— ëŒ€í•˜ì—¬ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”
    #     {question}
    # """
    #     )

        # 1. ëª¨ë¸ ìƒì„±
        llm = ChatOpenAI(streaming=True, callbacks=[stream_handler])

        # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system", 
                    "ì§ˆë¬¸ì— êµ¬ì–´ì²´ë¡œ ê¸¸ê²Œ ë‹µí•´ì£¼ì„¸ìš”. ",
                ),
                # ëŒ€í™” ê¸°ë¡ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©, historyê°€ MessageHistoryì˜ keyê°€ ë¨
                MessagesPlaceholder(variable_name="history"),
                ("human", "{question}"),   # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì…ë ¥
            ]
        )
        chain = prompt | llm

        # chain = prompt | ChatOpenAI()
        # response = chain.invoke({"question": user_input})


        chain_with_momory = (
            RunnableWithMessageHistory( # RunnableWithMessageHistory ê°ì²´ ìƒì„±
                chain,   # ì‹¤í–‰í•  Runnable ê°ì²´
                get_session_history,    # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
                input_messages_key="question",  # ì‚¬ìš©ì ì§ˆë¬¸ì˜ í‚¤
                history_messages_key="history", # ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤
            )
        )

        response = chain_with_momory.invoke(
            {"question": user_input},
            # ì„¸ì…˜ ID ì„¤ì •
            config={"configurable": {"session_id": session_id}},
        )
        msg = response.content
        # st.write(msg)
        st.session_state["messages"].append(ChatMessage(role="assistant", content=msg))
